{"version":3,"sources":["../../../src/utils/worker/pool.ts"],"names":["create","numWorkers","Math","max","reporter","verbose","worker","WorkerPool","require","resolve","env","GATSBY_NODE_GLOBALS","JSON","stringify","global","__GATSBY","GATSBY_WORKER_POOL_WORKER","GATSBY_SKIP_WRITING_SCHEMA_TO_FILE","queriesChunkSize","Number","process","GATSBY_PARALLEL_QUERY_CHUNK_SIZE","handleRunQueriesInWorkersQueueError","e","panic","id","context","error","runQueriesInWorkersQueue","pool","queryIds","opts","activity","createProgress","staticQueryIds","length","pageQueryIds","parentSpan","start","staticQuerySegments","chunkSize","pageQuerySegments","all","setComponents","segment","single","runQueries","then","replayWorkerActions","tick","catch","Promise","saveQueriesDependencies","end","mergeWorkerState","activityTimer","workerId","getWorkerInfo","state","String","queryStateChunk","queries","store","dispatch","type","payload","nextTick","actions","i","action"],"mappings":";;;;;;;;;AAAA;;AACA;;AACA;;AACA;;AAIA;;AACA;;AAGA;;AAKO,MAAMA,MAAM,GAAG,MAAwB;AAAA;;AAC5C,QAAMC,UAAU,GAAGC,IAAI,CAACC,GAAL,CAAS,CAAT,EAAY,uCAAiB,CAA7B,CAAnB;;AACAC,oBAASC,OAAT,CAAkB,YAAWJ,UAAW,SAAxC;;AAEA,QAAMK,MAAwB,GAAG,IAAIC,wBAAJ,CAAeC,OAAO,CAACC,OAAR,CAAiB,SAAjB,CAAf,EAA2C;AAC1ER,IAAAA,UAD0E;AAE1ES,IAAAA,GAAG,EAAE;AACHC,MAAAA,mBAAmB,EAAEC,IAAI,CAACC,SAAL,qBAAeC,MAAM,CAACC,QAAtB,+DAAkC,EAAlC,CADlB;AAEHC,MAAAA,yBAAyB,EAAG,MAFzB;AAGHC,MAAAA,kCAAkC,EAAG;AAHlC;AAFqE,GAA3C,CAAjC;AASA,uDAA+BX,MAA/B;AACA,qDAAmCA,MAAnC;AAEA,SAAOA,MAAP;AACD,CAjBM;;;AAmBP,MAAMY,gBAAgB,GACpBC,MAAM,CAACC,OAAO,CAACV,GAAR,CAAYW,gCAAb,CAAN,IAAwD,EAD1D;;AAGA,SAASC,mCAAT,CAA6CC,CAA7C,EAA8D;AAC5DnB,oBAASoB,KAAT,CAAe;AACbC,IAAAA,EAAE,EAAG,OADQ;AAEbC,IAAAA,OAAO,EAAE,EAFI;AAGbC,IAAAA,KAAK,EAAEJ;AAHM,GAAf;AAKD;;AAEM,eAAeK,wBAAf,CACLC,IADK,EAELC,QAFK,EAGLC,IAHK,EAOU;AACf,QAAMC,QAAQ,GAAG5B,kBAAS6B,cAAT,CACd,wBADc,EAEfH,QAAQ,CAACI,cAAT,CAAwBC,MAAxB,GAAiCL,QAAQ,CAACM,YAAT,CAAsBD,MAFxC,EAGf,CAHe,EAIf;AAAEE,IAAAA,UAAU,EAAEN,IAAF,aAAEA,IAAF,uBAAEA,IAAI,CAAEM;AAApB,GAJe,CAAjB;;AAMAL,EAAAA,QAAQ,CAACM,KAAT;;AACA,MAAI;AAAA;;AACF,UAAMC,mBAAmB,GAAG,mBAC1BT,QAAQ,CAACI,cADiB,qBAE1BH,IAF0B,aAE1BA,IAF0B,uBAE1BA,IAAI,CAAES,SAFoB,6DAEPtB,gBAFO,CAA5B;AAIA,UAAMuB,iBAAiB,GAAG,mBACxBX,QAAQ,CAACM,YADe,sBAExBL,IAFwB,aAExBA,IAFwB,uBAExBA,IAAI,CAAES,SAFkB,+DAELtB,gBAFK,CAA1B;AAKAW,IAAAA,IAAI,CAACa,GAAL,CAASC,aAAT;;AAEA,SAAK,MAAMC,OAAX,IAAsBL,mBAAtB,EAA2C;AACzCV,MAAAA,IAAI,CAACgB,MAAL,CACGC,UADH,CACc;AAAEV,QAAAA,YAAY,EAAE,EAAhB;AAAoBF,QAAAA,cAAc,EAAEU;AAApC,OADd,EAEGG,IAFH,CAEQC,mBAFR,EAGGD,IAHH,CAGQ,MAAM;AACVf,QAAAA,QAAQ,CAACiB,IAAT,CAAcL,OAAO,CAACT,MAAtB;AACD,OALH,EAMGe,KANH,CAMS5B,mCANT;AAOD;;AAED,SAAK,MAAMsB,OAAX,IAAsBH,iBAAtB,EAAyC;AACvCZ,MAAAA,IAAI,CAACgB,MAAL,CACGC,UADH,CACc;AAAEV,QAAAA,YAAY,EAAEQ,OAAhB;AAAyBV,QAAAA,cAAc,EAAE;AAAzC,OADd,EAEGa,IAFH,CAEQC,mBAFR,EAGGD,IAHH,CAGQ,MAAM;AACVf,QAAAA,QAAQ,CAACiB,IAAT,CAAcL,OAAO,CAACT,MAAtB;AACD,OALH,EAMGe,KANH,CAMS5B,mCANT;AAOD,KA9BC,CAgCF;AACA;AACA;;;AACA,UAAM6B,OAAO,CAACT,GAAR,CAAYb,IAAI,CAACa,GAAL,CAASU,uBAAT,EAAZ,CAAN;AACD,GApCD,CAoCE,OAAO7B,CAAP,EAAU;AACVD,IAAAA,mCAAmC,CAACC,CAAD,CAAnC;AACD,GAtCD,SAsCU;AACRS,IAAAA,QAAQ,CAACqB,GAAT;AACD;AACF;;AAEM,eAAeC,gBAAf,CACLzB,IADK,EAELQ,UAFK,EAGU;AACf,QAAML,QAAQ,GAAG5B,kBAASmD,aAAT,CAAwB,oBAAxB,EAA6C;AAAElB,IAAAA;AAAF,GAA7C,CAAjB;;AACAL,EAAAA,QAAQ,CAACM,KAAT;;AAEA,OAAK,MAAM;AAAEkB,IAAAA;AAAF,GAAX,IAA2B3B,IAAI,CAAC4B,aAAL,EAA3B,EAAiD;AAC/C,UAAMC,KAAK,GAAG,qCAAyB,CAAE,SAAF,CAAzB,EAAsCC,MAAM,CAACH,QAAD,CAA5C,CAAd;AACA,UAAMI,eAAe,GAAGF,KAAK,CAACG,OAA9B;;AACA,QAAID,eAAJ,EAAqB;AACnB;AACAE,mBAAMC,QAAN,CAAe;AACbC,QAAAA,IAAI,EAAG,0BADM;AAEbC,QAAAA,OAAO,EAAE;AACPT,UAAAA,QADO;AAEPI,UAAAA;AAFO;AAFI,OAAf;;AAOA,YAAM,IAAIT,OAAJ,CAAY1C,OAAO,IAAIW,OAAO,CAAC8C,QAAR,CAAiBzD,OAAjB,CAAvB,CAAN;AACD;AACF;;AACDuB,EAAAA,QAAQ,CAACqB,GAAT;AACD;;AAED,eAAeL,mBAAf,CACEmB,OADF,EAEiB;AACf,MAAIC,CAAC,GAAG,CAAR;;AACA,OAAK,MAAMC,MAAX,IAAqBF,OAArB,EAA8B;AAC5BL,iBAAMC,QAAN,CAAeM,MAAf,EAD4B,CAG5B;;;AACA,QAAID,CAAC,KAAK,GAAN,KAAc,CAAlB,EAAqB;AACnB,YAAM,IAAIjB,OAAJ,CAAY1C,OAAO,IAAIW,OAAO,CAAC8C,QAAR,CAAiBzD,OAAjB,CAAvB,CAAN;AACD;AACF;AACF","sourcesContent":["import { WorkerPool } from \"gatsby-worker\"\nimport { chunk } from \"lodash\"\nimport reporter from \"gatsby-cli/lib/reporter\"\nimport { cpuCoreCount } from \"gatsby-core-utils\"\nimport { Span } from \"opentracing\"\n\nimport { IGroupedQueryIds } from \"../../services\"\nimport { initJobsMessagingInMainProcess } from \"../jobs/worker-messaging\"\nimport { initReporterMessagingInMainProcess } from \"./reporter\"\n\nimport { GatsbyWorkerPool } from \"./types\"\nimport { loadPartialStateFromDisk, store } from \"../../redux\"\nimport { ActionsUnion, IGatsbyState } from \"../../redux/types\"\n\nexport type { GatsbyWorkerPool }\n\nexport const create = (): GatsbyWorkerPool => {\n  const numWorkers = Math.max(1, cpuCoreCount() - 1)\n  reporter.verbose(`Creating ${numWorkers} worker`)\n\n  const worker: GatsbyWorkerPool = new WorkerPool(require.resolve(`./child`), {\n    numWorkers,\n    env: {\n      GATSBY_NODE_GLOBALS: JSON.stringify(global.__GATSBY ?? {}),\n      GATSBY_WORKER_POOL_WORKER: `true`,\n      GATSBY_SKIP_WRITING_SCHEMA_TO_FILE: `true`,\n    },\n  })\n\n  initJobsMessagingInMainProcess(worker)\n  initReporterMessagingInMainProcess(worker)\n\n  return worker\n}\n\nconst queriesChunkSize =\n  Number(process.env.GATSBY_PARALLEL_QUERY_CHUNK_SIZE) || 50\n\nfunction handleRunQueriesInWorkersQueueError(e: Error): never {\n  reporter.panic({\n    id: `85928`,\n    context: {},\n    error: e,\n  })\n}\n\nexport async function runQueriesInWorkersQueue(\n  pool: GatsbyWorkerPool,\n  queryIds: IGroupedQueryIds,\n  opts?: {\n    chunkSize?: number\n    parentSpan?: Span\n  }\n): Promise<void> {\n  const activity = reporter.createProgress(\n    `run queries in workers`,\n    queryIds.staticQueryIds.length + queryIds.pageQueryIds.length,\n    0,\n    { parentSpan: opts?.parentSpan }\n  )\n  activity.start()\n  try {\n    const staticQuerySegments = chunk(\n      queryIds.staticQueryIds,\n      opts?.chunkSize ?? queriesChunkSize\n    )\n    const pageQuerySegments = chunk(\n      queryIds.pageQueryIds,\n      opts?.chunkSize ?? queriesChunkSize\n    )\n\n    pool.all.setComponents()\n\n    for (const segment of staticQuerySegments) {\n      pool.single\n        .runQueries({ pageQueryIds: [], staticQueryIds: segment })\n        .then(replayWorkerActions)\n        .then(() => {\n          activity.tick(segment.length)\n        })\n        .catch(handleRunQueriesInWorkersQueueError)\n    }\n\n    for (const segment of pageQuerySegments) {\n      pool.single\n        .runQueries({ pageQueryIds: segment, staticQueryIds: [] })\n        .then(replayWorkerActions)\n        .then(() => {\n          activity.tick(segment.length)\n        })\n        .catch(handleRunQueriesInWorkersQueueError)\n    }\n\n    // note that we only await on this and not on anything before (`.setComponents()` or `.runQueries()`)\n    // because gatsby-worker will queue tasks internally and worker will never execute multiple tasks at the same time\n    // so awaiting `.saveQueriesDependencies()` is enough to make sure `.setComponents()` and `.runQueries()` finished\n    await Promise.all(pool.all.saveQueriesDependencies())\n  } catch (e) {\n    handleRunQueriesInWorkersQueueError(e)\n  } finally {\n    activity.end()\n  }\n}\n\nexport async function mergeWorkerState(\n  pool: GatsbyWorkerPool,\n  parentSpan?: Span\n): Promise<void> {\n  const activity = reporter.activityTimer(`Merge worker state`, { parentSpan })\n  activity.start()\n\n  for (const { workerId } of pool.getWorkerInfo()) {\n    const state = loadPartialStateFromDisk([`queries`], String(workerId))\n    const queryStateChunk = state.queries as IGatsbyState[\"queries\"]\n    if (queryStateChunk) {\n      // When there are too little queries, some worker can be inactive and its state is empty\n      store.dispatch({\n        type: `MERGE_WORKER_QUERY_STATE`,\n        payload: {\n          workerId,\n          queryStateChunk,\n        },\n      })\n      await new Promise(resolve => process.nextTick(resolve))\n    }\n  }\n  activity.end()\n}\n\nasync function replayWorkerActions(\n  actions: Array<ActionsUnion>\n): Promise<void> {\n  let i = 1\n  for (const action of actions) {\n    store.dispatch(action)\n\n    // Give event loop some breath\n    if (i++ % 100 === 0) {\n      await new Promise(resolve => process.nextTick(resolve))\n    }\n  }\n}\n"],"file":"pool.js"}